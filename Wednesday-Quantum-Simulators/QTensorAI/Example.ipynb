{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QTensorAI Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start using QTensorAI for your own hybrid quantum-classical neural network research, you need to do a few things.\n",
    "1. Write your own circuit composer.\n",
    "2. Write your own hybrid pytorch neural network module.\n",
    "\n",
    "The circuit composer is what you use to create your circuit, and the hybrid module is what you use to integrate with a machine learning pipeline.\n",
    "\n",
    "We have built base classes of circuit composers and hybrid modules that allows you to focus on the science of your study, rather than the implementation details of our library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Circuit Composer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to create a straight forward quantum neural network as is described by Abbas et. al. in arXiv:2011.00027. We will not focus on the circuit, but on how you can use our library. First, let us import the class that facilitates your creation of a custom circuit composer. This class is the `ParallelComposer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hl8967/.conda/envs/qtensor_ai/lib/python3.9/site-packages/tqdm-4.63.0-py3.9.egg/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qtensor_ai import ParallelComposer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can create our own composer inheriting from the `ParallelComposer` class. This composer is also provided in `examples/Custom_Circuit_Composers.py`. The comments in this notebook are made with a narrative flow and is best to read without skipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNNComposer(ParallelComposer):\n",
    "    \n",
    "    '''For initialization, n_qubits is always needed since the ParallelComposer class requires that\n",
    "    The other parameters are specific to this example and are not important.'''\n",
    "    def __init__(self, n_qubits, n_layers, higher_order=False):\n",
    "        self.n_layers = n_layers\n",
    "        self.higher_order = higher_order\n",
    "        super().__init__(n_qubits)\n",
    "    \n",
    "    '''This creates a layer of Hadamard gates. To apply any gates,\n",
    "    use self.apply_gate(self.operators.gate, *qubits, **parameters).\n",
    "    There can be mulple qubits or parameters, depending on the gate type.\n",
    "    Other functions below are logics to add gates. We can ignore them for now.'''\n",
    "    def layer_of_Hadamards(self):\n",
    "        for q in self.qubits:\n",
    "            self.apply_gate(self.operators.H, q)\n",
    "    \n",
    "    def entangling_layer(self):\n",
    "        for i in range(self.n_qubits//2):\n",
    "            control_qubit = self.qubits[2*i]\n",
    "            target_qubit = self.qubits[2*i+1]\n",
    "            self.apply_gate(self.operators.cX, control_qubit, target_qubit)\n",
    "        for i in range((self.n_qubits+1)//2-1):\n",
    "            control_qubit = self.qubits[2*i+1]\n",
    "            target_qubit = self.qubits[2*i+2]\n",
    "            '''For example, you can put two qubits for CNOT (cX) gates.'''\n",
    "            self.apply_gate(self.operators.cX, control_qubit, target_qubit)\n",
    "        control_qubit = self.qubits[-1]\n",
    "        target_qubit = self.qubits[0]\n",
    "    \n",
    "    def encoding_circuit(self, data):\n",
    "        self.layer_of_Hadamards()\n",
    "        for i, qubit in enumerate(self.qubits):\n",
    "            self.apply_gate(self.operators.ZPhase, qubit, alpha=data[:, i])\n",
    "        if self.higher_order:\n",
    "            for i in range(self.n_qubits):\n",
    "                for j in range(i+1, self.n_qubits):\n",
    "                    control_qubit = self.qubits[i]\n",
    "                    target_qubit = self.qubits[j]\n",
    "                    self.apply_gate(self.operators.cX, control_qubit, target_qubit)\n",
    "                    self.apply_gate(self.operators.ZPhase, target_qubit, alpha=data[:, i]*data[:, j])\n",
    "                    self.apply_gate(self.operators.cX, control_qubit, target_qubit)\n",
    "    \n",
    "    def variational_layer(self, layer, layer_params):\n",
    "        for i in range(self.n_qubits):\n",
    "            qubit = self.qubits[i]\n",
    "            '''For an RY (YPhase) gate, there is one qubit,\n",
    "            and a alpha parameter which is a torch.Tensor of size (n_batch, 1).'''\n",
    "            self.apply_gate(self.operators.YPhase, qubit, alpha=layer_params[:, i])\n",
    "     \n",
    "    def cost_operator(self):\n",
    "        for qubit in self.qubits:\n",
    "            self.apply_gate(self.operators.Z, qubit)\n",
    "\n",
    "    def forward_circuit(self, data, params):\n",
    "        self.encoding_circuit(data)\n",
    "        self.entangling_layer()\n",
    "        for layer in range(self.n_layers):\n",
    "            self.variational_layer(layer, params[:, :, layer])\n",
    "            self.entangling_layer()\n",
    "    '''The detailed inputs of apply_gate will depend on the gate, and you can implement\n",
    "    custom gates as well. For those, you could ask for any fancy input parameters.\n",
    "\n",
    "    Moving on, with all the functions for building the circuit ready, we can implement\n",
    "    required functions. Specifically, any custom composers must have update_full_circuit\n",
    "    and name.\n",
    "\n",
    "    This function builds circuit whose first amplitude is the expectation value of\n",
    "    the measured circuit w.r.t. the cost_operator.\n",
    "    This function needs to return the circuit (a list) whose first amplitude you want to simulate.'''\n",
    "    def updated_full_circuit(self, **parameters):\n",
    "        data = parameters['data']\n",
    "        params = parameters['params']\n",
    "        '''All the apply_gate operations actually appends the gates to self.builder.circuit.\n",
    "        Hence, after we call the functions that builds the circuits, wee need to fetch the\n",
    "        circuit from self.builder. We will also need to clean the builder up from time to time.'''\n",
    "        self.builder.reset() # Clear builder.circuit\n",
    "        self.forward_circuit(data, params) # Set builder.circuit to the forward circuit according to data and params\n",
    "        self.cost_operator() # Add the cost operators to builder.circuit\n",
    "        first_part = self.builder.circuit # Extract builder.circuit at this stage for later use\n",
    "        self.builder.reset() # Clear builder.circuit\n",
    "        self.forward_circuit(data, params) # Set builder.circuit to the forward circuit according to data and params\n",
    "        self.builder.inverse() # Change builder.circuit to it's reverse, which is the forward circuit in reverse\n",
    "        second_part = self.builder.circuit # Extract the inverse circuit\n",
    "        self.builder.reset() # Clear builder circuit\n",
    "        '''The final circuit is forward + cost + inverse.\n",
    "        The first amplitude is the expectation value of the cost operator\n",
    "        for the forward circuit initialized with the 0 state.'''\n",
    "        return first_part + second_part\n",
    "    '''Although this function returns a circuit, we should not call this function in general.\n",
    "    This is because the parent class uses this function for the produce_circuit method to\n",
    "    generate the circuit and tensors on the GPU behind the scene.'''\n",
    "\n",
    "    '''This function returns the name of the circuit composer'''\n",
    "    def name(self):\n",
    "        return 'QNN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap, you need to initialize the `ParallelComposer` class with `n_qubits`, call `self.apply_gate` to add gates to `self.builder.circuit`, and create the `update_full_circuit` method which returns the circuit whose first amplitude you want to simulate. Finally, create the `name` method.\n",
    "\n",
    "## Custom Hybrid Module\n",
    "\n",
    "Now, let us move on to creating a custom hybrid module that can interface with a machine learning pipeline. First, import the `HybridModule` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qtensor_ai import HybridModule, DefaultOptimizer\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also include the `DefaultOptimizer` class to put in as the default choice for the optimizer. We will create a drop-in replacement of a classical fully connected layer called `QNN`. This can also be found in `examples/Custom_Modules.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This is a drop-in replacement of linear layers.\n",
    "The number of input features is the number of qubits.\n",
    "Each output feature is computed by an independently parameterized circuit'''\n",
    "class QNN(HybridModule):\n",
    "    \n",
    "    def __init__(self, in_features, out_features, variational_layers=1, higher_order=False, optimizer=DefaultOptimizer()):\n",
    "                \n",
    "        '''Initializing module parameters\n",
    "        The variable circuit_name is needed for initialization of the parent class HybridModule\n",
    "        All the other attributes are unique to this circuit and we can ignore.'''\n",
    "        circuit_name = 'n_{}_l_{}'.format(in_features, variational_layers)\n",
    "        self.higher_order = higher_order\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.variational_layers = variational_layers\n",
    "        self.higher_order = higher_order\n",
    "        \n",
    "        '''Define the circuit composer and initialize the hybrid module.\n",
    "        The composer is the custom composer we just defined.'''\n",
    "        composer = QNNComposer(in_features, variational_layers, higher_order=higher_order)\n",
    "        super(QNN, self).__init__(circuit_name=circuit_name, composer=composer, optimizer=optimizer)\n",
    "\n",
    "        '''self.weight are model weights. Weights must be defined after super().__init__()'''\n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_features, variational_layers, dtype=torch.float32))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''These lines of code are trying to manipulate the array to give the right input to the simulation.\n",
    "        The circuits with different parameters will be simulated in a batch parallel manner.\n",
    "        The 0-th dimension is the parallel batch dimension.'''\n",
    "        n_batch = x.shape[0] # (n_batch, in_features)\n",
    "        # Because for multiple output features, the parallelism is in the batch dimension as well as the\n",
    "        # output feature size dimension, we need to make the 0-th dimension of size out_features*n_batch\n",
    "        x = x.repeat(self.out_features, 1) # (out_features*n_batch, in_features)\n",
    "        params = self.weight.unsqueeze(1) # (out_features, 1, in_features, variational_layers)\n",
    "        params = params.expand(-1, n_batch, -1, -1) # (out_features, n_batch, in_features, variational_layers)\n",
    "        params = params.reshape(self.out_features*n_batch, self.in_features, self.variational_layers) # (out_features*n_batch, in_features, variational_layers)\n",
    "\n",
    "        '''The actual simulation must be run by calling the parent_forward method of the parent class. \n",
    "        The parameters should be the same parameters as those accepted by the circuit composer'''\n",
    "        out = self.parent_forward(data=x, params=params) # (out_features*n_batch)\n",
    "        # Reshaping the outputs\n",
    "        out = torch.real(out) # (out_features*n_batch)\n",
    "        out = out.reshape(self.out_features, n_batch) # (out_features, n_batch)\n",
    "        out = out.permute(1, 0) # (n_batch, out_features)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap, we need to have a `circuit_name`, initialize the `HybridModule` parent class with your circuit name, composer and optimizer, and only after super init create any model weights. Finally, to run the simulation, `self.parent_forward` must be used in `forward`.\n",
    "\n",
    "## Bringing Everything Together\n",
    "\n",
    "Now let us test if our model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QNN weight before training:  tensor([-1.9620,  0.8190,  1.4865,  1.9406, -0.6534,  1.2902, -0.5050,  2.1383,\n",
      "        -0.0538,  0.1149], grad_fn=<SqueezeBackward0>)\n",
      "Using previously saved contraction order at  <_io.BufferedReader name='/home/hl8967/Saved_Contraction_Orders/OrderingOptimizer/QNN/n_10_l_1.pickle'>\n",
      "tensor(0.8355, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8332, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8309, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8286, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8263, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8239, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8216, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8191, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8167, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8142, grad_fn=<MseLossBackward0>)\n",
      "QNN weight after training:  tensor([-1.9518,  0.8190,  1.4964,  1.9406, -0.6432,  1.2902, -0.4984,  2.1383,\n",
      "        -0.0538,  0.1251], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from qtensor_ai import DefaultOptimizer\n",
    "\n",
    "in_features = 10\n",
    "out_features = 10\n",
    "variational_layers = 1\n",
    "optimizer = DefaultOptimizer()\n",
    "epochs = 10\n",
    "\n",
    "'''Creating an instance of our custom hybrid module'''\n",
    "qnn = QNN(in_features, out_features, variational_layers=variational_layers, optimizer=optimizer)\n",
    "\n",
    "'''Make a hybrid neural network'''\n",
    "model = nn.Sequential(nn.Linear(in_features,in_features),\n",
    "                    nn.ReLU(),\n",
    "                    qnn,\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(out_features,1),\n",
    "                    nn.ReLU())\n",
    "\n",
    "'''Define the machine learning optimizer and loss function'''\n",
    "torch_optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.functional.mse_loss\n",
    "\n",
    "'''Create some random data. Output is fixed so that we can learn it and see the loss decrease'''\n",
    "x = torch.rand(1000, in_features)\n",
    "y = torch.ones(1000, 1)\n",
    "\n",
    "print('QNN weight before training: ', qnn.weight[1].squeeze())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    y_hat = model(x)\n",
    "    loss = loss_fn(y, y_hat)\n",
    "    torch_optim.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    print(loss)\n",
    "    torch_optim.step()\n",
    "\n",
    "print('QNN weight after training: ', qnn.weight[1].squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the loss indeed decreases and our quantum module parameters also changed after learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance and Choosing Optimizers\n",
    "\n",
    "For simulating larger circuits, one needs to use the `TamakiOptimizer`, which optimizes the contraction order with the state-of-the-art method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QNN weight before training:  tensor([[-0.1719, -0.5676, -0.9996, -0.5885],\n",
      "        [-1.7975,  0.7700,  0.4302, -1.1895],\n",
      "        [ 0.1623, -0.5708,  0.0832, -0.4439],\n",
      "        [ 0.6429,  1.8144,  0.3344,  0.4775],\n",
      "        [-0.1656,  0.9729, -2.2048,  0.6325]], grad_fn=<SqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=None, width=None\n",
      "Time=11562, width=11\n",
      "Time=11562, width=11\n",
      "Time=11562, width=11\n",
      "Time=11562, width=11\n",
      "Time=11562, width=11\n",
      "Time=11562, width=11\n",
      "Time=11562, width=11\n",
      "Time=11562, width=11\n",
      "Time=11562, width=11\n",
      "Time=11562, width=11\n",
      "Time=11562, width=11\n",
      "Time=11562, width=11\n",
      "Time=11562, width=11\n",
      "Time=11562, width=11\n",
      "Time=11562, width=11\n",
      "Exception: Timeout. Stoppnig tamaki\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New contraction order, save at  <_io.BufferedWriter name='/home/hl8967/Saved_Contraction_Orders/TamakiOptimizer/QNN/wait_time_20/n_20_l_4.pickle'>\n",
      "tensor(0.9838, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9815, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9792, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9769, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9745, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9722, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9698, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9673, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9649, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9624, grad_fn=<MseLossBackward0>)\n",
      "Time taken for training: 3.906189441680908 seconds.\n",
      "QNN weight after training:  tensor([[-0.1820, -0.5575, -0.9895, -0.5783],\n",
      "        [-1.7947,  0.7772,  0.4373, -1.1895],\n",
      "        [ 0.1521, -0.5607,  0.0931, -0.4419],\n",
      "        [ 0.6530,  1.8245,  0.3296,  0.4775],\n",
      "        [-0.1581,  0.9791, -2.2118,  0.6426]], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from qtensor_ai import TamakiOptimizer\n",
    "import time\n",
    "\n",
    "in_features = 20\n",
    "out_features = 10\n",
    "variational_layers = 4\n",
    "optimizer = TamakiOptimizer(wait_time=20)\n",
    "epochs = 10\n",
    "\n",
    "qnn = QNN(in_features, out_features, variational_layers=variational_layers, optimizer=optimizer)\n",
    "\n",
    "model = nn.Sequential(nn.Linear(in_features, in_features),\n",
    "                    nn.ReLU(),\n",
    "                    qnn,\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(out_features, 1),\n",
    "                    nn.ReLU())\n",
    "\n",
    "torch_optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.functional.mse_loss\n",
    "\n",
    "x = torch.rand(10, in_features)\n",
    "y = torch.ones(10, 1)\n",
    "\n",
    "print('QNN weight before training: ', qnn.weight[1,:5].squeeze())\n",
    "\n",
    "'''The first Contraction Order optimization takes place here, which takes a long time.\n",
    "To accurately time the computation itself, we only time aftr the first run.'''\n",
    "y_hat = model(x)\n",
    "start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    y_hat = model(x)\n",
    "    loss = loss_fn(y, y_hat)\n",
    "    torch_optim.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    print(loss)\n",
    "    torch_optim.step()\n",
    "\n",
    "stop = time.time()\n",
    "print('Time taken for training: {} seconds.'.format(stop-start))\n",
    "print('QNN weight after training: ', qnn.weight[1,:5].squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TamakiOptimizer with 20 seconds of optimization time takes 4 seconds to run 10 epochs. The loss value fluctuates greatly depending on the initial condition and is not indicative of the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QNN weight before training:  tensor([[ 0.3343,  1.4748, -0.2820, -0.6933],\n",
      "        [ 0.9820, -0.4376,  1.2630, -0.5573],\n",
      "        [-0.2909,  2.0450,  0.3828,  0.4420],\n",
      "        [-0.2617,  1.1508,  0.2216, -0.4555],\n",
      "        [-0.0056,  0.6277, -0.8806,  0.6953]], grad_fn=<SqueezeBackward0>)\n",
      "New contraction order, save at  <_io.BufferedWriter name='/home/hl8967/Saved_Contraction_Orders/OrderingOptimizer/QNN/n_20_l_4.pickle'>\n",
      "tensor(0.7491, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7472, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7454, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7436, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7418, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7400, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7382, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7364, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7346, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7328, grad_fn=<MseLossBackward0>)\n",
      "Time taken for training: 34.151867389678955 seconds.\n",
      "QNN weight after training:  tensor([[ 3.3190e-01,  1.4721e+00, -2.9022e-01, -6.8696e-01],\n",
      "        [ 9.9212e-01, -4.2744e-01,  1.2528e+00, -5.5725e-01],\n",
      "        [-2.8087e-01,  2.0355e+00,  3.7268e-01,  4.3277e-01],\n",
      "        [-2.7183e-01,  1.1606e+00,  2.1159e-01, -4.5555e-01],\n",
      "        [ 2.4653e-05,  6.1755e-01, -8.7047e-01,  6.8901e-01]],\n",
      "       grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "in_features = 20\n",
    "out_features = 10\n",
    "variational_layers = 4\n",
    "optimizer = DefaultOptimizer()\n",
    "epochs = 10\n",
    "\n",
    "'''Creating an instance of our custom hybrid module'''\n",
    "qnn = QNN(in_features, out_features, variational_layers=variational_layers, optimizer=optimizer)\n",
    "\n",
    "'''Make a hybrid neural network'''\n",
    "model = nn.Sequential(nn.Linear(in_features, in_features),\n",
    "                    nn.ReLU(),\n",
    "                    qnn,\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(out_features, 1),\n",
    "                    nn.ReLU())\n",
    "\n",
    "'''Define the machine learning optimizer and loss function'''\n",
    "torch_optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.functional.mse_loss\n",
    "\n",
    "'''Create some random data. Output is fixed so that we can learn it and see the loss decrease'''\n",
    "x = torch.rand(10, in_features)\n",
    "y = torch.ones(10, 1)\n",
    "\n",
    "print('QNN weight before training: ', qnn.weight[1,:5].squeeze())\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    y_hat = model(x)\n",
    "    loss = loss_fn(y, y_hat)\n",
    "    torch_optim.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    print(loss)\n",
    "    torch_optim.step()\n",
    "\n",
    "stop = time.time()\n",
    "print('Time taken for training: {} seconds.'.format(stop-start))\n",
    "print('QNN weight after training: ', qnn.weight[1,:5].squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default optimizer takes 35 seconds to complete 10 epochs. What is not shown here is the much higher memory consumption as well. In general, using the TamakiOptimizer is highly advantageous for simulating more challenging circuits."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9573c475ae947fc4c73ea79e643e7b87a0dff7cbdfd0f21335f7c021a88741d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
